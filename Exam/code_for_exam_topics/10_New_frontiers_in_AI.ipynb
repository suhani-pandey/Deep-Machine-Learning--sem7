{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "b6F1cjn5BOc3"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from collections import defaultdict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### emerging direction in deep learning : LLms and generative model"
      ],
      "metadata": {
        "id": "oXvTZdyoCBSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Large Language Models (LLMs) ---\n",
        "class SimpleLLM:\n",
        "    def __init__(self):\n",
        "        self.name = \"Simple LLM\"\n",
        "        # Simplified vocabulary\n",
        "        self.vocab = [\"the\", \"cat\", \"dog\", \"sits\", \"runs\", \"on\", \"mat\", \"park\", \"is\", \"happy\"]\n",
        "        self.context_window = 5  # How many tokens to consider\n",
        "\n",
        "        # Simplified \"knowledge\" - word associations\n",
        "        self.word_associations = {\n",
        "            \"cat\": [\"sits\", \"runs\", \"is\", \"happy\"],\n",
        "            \"dog\": [\"runs\", \"sits\", \"is\", \"happy\"],\n",
        "            \"sits\": [\"on\", \"the\"],\n",
        "            \"runs\": [\"in\", \"to\", \"the\"],\n",
        "            \"the\": [\"cat\", \"dog\", \"mat\", \"park\"]\n",
        "        }\n",
        "\n",
        "        print(f\"=== {self.name} INITIALIZED ===\")\n",
        "        print(f\"Vocabulary size: {len(self.vocab)}\")\n",
        "        print(f\"Context window: {self.context_window}\")\n",
        "        print()\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        \"\"\"Convert text to tokens (simplified)\"\"\"\n",
        "        tokens = text.lower().split()\n",
        "        print(f\"Tokenization: '{text}' → {tokens}\")\n",
        "        return tokens\n",
        "\n",
        "    def generate_next_token(self, context):\n",
        "        \"\"\"Generate next token based on context (simplified attention)\"\"\"\n",
        "        print(f\"Context: {context}\")\n",
        "\n",
        "        if not context:\n",
        "            next_token = random.choice(self.vocab)\n",
        "        else:\n",
        "            last_word = context[-1]\n",
        "            if last_word in self.word_associations:\n",
        "                # Simplified \"attention\" - focus on last word\n",
        "                possible_next = self.word_associations[last_word]\n",
        "                next_token = random.choice(possible_next)\n",
        "                print(f\"Attention: '{last_word}' → possible next: {possible_next}\")\n",
        "            else:\n",
        "                next_token = random.choice(self.vocab)\n",
        "\n",
        "        print(f\"Generated token: {next_token}\")\n",
        "        return next_token\n",
        "\n",
        "    def generate_text(self, prompt, max_length=8):\n",
        "        \"\"\"Generate text continuation\"\"\"\n",
        "        print(f\"=== TEXT GENERATION ===\")\n",
        "        print(f\"Prompt: '{prompt}'\")\n",
        "\n",
        "        tokens = self.tokenize(prompt)\n",
        "        generated = tokens.copy()\n",
        "\n",
        "        for i in range(max_length - len(tokens)):\n",
        "            # Use only recent context (context window)\n",
        "            context = generated[-self.context_window:]\n",
        "            next_token = self.generate_next_token(context)\n",
        "            generated.append(next_token)\n",
        "\n",
        "            print(f\"Step {i+1}: {' '.join(generated)}\")\n",
        "\n",
        "        final_text = ' '.join(generated)\n",
        "        print(f\"Final output: '{final_text}'\")\n",
        "        return final_text"
      ],
      "metadata": {
        "id": "MUdPd9OnCE31"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Generative Adversarial Networks (GANs) ---\n",
        "class SimpleGAN:\n",
        "    def __init__(self):\n",
        "        self.name = \"Simple GAN\"\n",
        "        print(f\"=== {self.name} ===\")\n",
        "        print(\"Two networks competing: Generator vs Discriminator\")\n",
        "\n",
        "        # Simplified \"real\" data (simple patterns)\n",
        "        self.real_data = [\n",
        "            [1, 1, 0, 0],  # Pattern 1\n",
        "            [0, 0, 1, 1],  # Pattern 2\n",
        "            [1, 0, 1, 0],  # Pattern 3\n",
        "        ]\n",
        "\n",
        "        # Generator starts with random ability\n",
        "        self.generator_skill = 0.1\n",
        "        # Discriminator starts with random ability\n",
        "        self.discriminator_skill = 0.1\n",
        "\n",
        "        print(f\"Real data patterns: {self.real_data}\")\n",
        "        print()\n",
        "\n",
        "    def generator_create_fake(self):\n",
        "        \"\"\"Generator creates fake data\"\"\"\n",
        "        if random.random() < self.generator_skill:\n",
        "            # As generator improves, creates more realistic data\n",
        "            fake_data = random.choice(self.real_data).copy()\n",
        "            # Add some noise\n",
        "            if random.random() < 0.3:\n",
        "                fake_data[random.randint(0, 3)] = 1 - fake_data[random.randint(0, 3)]\n",
        "        else:\n",
        "            # Poor generator creates random data\n",
        "            fake_data = [random.randint(0, 1) for _ in range(4)]\n",
        "\n",
        "        print(f\"Generator created: {fake_data}\")\n",
        "        return fake_data\n",
        "\n",
        "    def discriminator_judge(self, data):\n",
        "        \"\"\"Discriminator tries to identify real vs fake\"\"\"\n",
        "        is_real = data in self.real_data\n",
        "\n",
        "        # Discriminator's judgment (improves over time)\n",
        "        if random.random() < self.discriminator_skill:\n",
        "            judgment = is_real  # Correct judgment\n",
        "        else:\n",
        "            judgment = not is_real  # Wrong judgment\n",
        "\n",
        "        print(f\"Discriminator judges {data} as {'REAL' if judgment else 'FAKE'}\")\n",
        "        print(f\"Actual truth: {'REAL' if is_real else 'FAKE'}\")\n",
        "\n",
        "        return judgment, is_real\n",
        "\n",
        "    def train_one_round(self):\n",
        "        \"\"\"One round of GAN training\"\"\"\n",
        "        print(f\"=== GAN TRAINING ROUND ===\")\n",
        "\n",
        "        # Generator creates fake data\n",
        "        fake_data = self.generator_create_fake()\n",
        "\n",
        "        # Discriminator judges fake data\n",
        "        judgment, truth = self.discriminator_judge(fake_data)\n",
        "\n",
        "        # Update skills based on performance\n",
        "        if judgment == truth:\n",
        "            # Discriminator was correct\n",
        "            self.discriminator_skill = min(0.9, self.discriminator_skill + 0.1)\n",
        "            print(\"Discriminator improved!\")\n",
        "        else:\n",
        "            # Generator fooled discriminator\n",
        "            self.generator_skill = min(0.9, self.generator_skill + 0.1)\n",
        "            print(\"Generator improved!\")\n",
        "\n",
        "        print(f\"Generator skill: {self.generator_skill:.1f}\")\n",
        "        print(f\"Discriminator skill: {self.discriminator_skill:.1f}\")\n",
        "        print()"
      ],
      "metadata": {
        "id": "GIRn9RUbCNvK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Variational Autoencoders (VAE) ---\n",
        "class SimpleVAE:\n",
        "    def __init__(self):\n",
        "        self.name = \"Simple VAE\"\n",
        "        print(f\"=== {self.name} ===\")\n",
        "        print(\"Encode data → Latent space → Decode data\")\n",
        "\n",
        "        # Sample data: simple 2D points\n",
        "        self.data_points = [\n",
        "            [1, 1], [1, 2], [2, 1], [2, 2],  # Cluster 1\n",
        "            [5, 5], [5, 6], [6, 5], [6, 6]   # Cluster 2\n",
        "        ]\n",
        "\n",
        "        print(f\"Training data: {self.data_points}\")\n",
        "        print()\n",
        "\n",
        "    def encode_to_latent(self, data_point):\n",
        "        \"\"\"Encode data point to latent representation\"\"\"\n",
        "        # Simplified encoding: compress 2D to 1D\n",
        "        # Add some noise (VAE characteristic)\n",
        "        latent = sum(data_point) / 2 + random.uniform(-0.5, 0.5)\n",
        "        print(f\"Encode {data_point} → latent: {latent:.2f}\")\n",
        "        return latent\n",
        "\n",
        "    def decode_from_latent(self, latent):\n",
        "        \"\"\"Decode from latent space back to data space\"\"\"\n",
        "        # Simplified decoding: expand 1D to 2D\n",
        "        # Add reconstruction noise\n",
        "        decoded = [\n",
        "            latent + random.uniform(-0.5, 0.5),\n",
        "            latent + random.uniform(-0.5, 0.5)\n",
        "        ]\n",
        "        print(f\"Decode latent {latent:.2f} → {[round(x, 1) for x in decoded]}\")\n",
        "        return decoded\n",
        "\n",
        "    def generate_new_sample(self):\n",
        "        \"\"\"Generate new sample by sampling latent space\"\"\"\n",
        "        print(\"=== VAE GENERATION ===\")\n",
        "\n",
        "        # Sample from latent space\n",
        "        sampled_latent = random.uniform(1, 6)  # Between our two clusters\n",
        "        print(f\"Sampled latent: {sampled_latent:.2f}\")\n",
        "\n",
        "        # Decode to get new data point\n",
        "        generated = self.decode_from_latent(sampled_latent)\n",
        "        print(f\"Generated new sample: {[round(x, 1) for x in generated]}\")\n",
        "        return generated"
      ],
      "metadata": {
        "id": "MjR3bVWtCT2P"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Diffusion Models ---\n",
        "class SimpleDiffusion:\n",
        "    def __init__(self):\n",
        "        self.name = \"Simple Diffusion Model\"\n",
        "        print(f\"=== {self.name} ===\")\n",
        "        print(\"Forward: Add noise step by step\")\n",
        "        print(\"Reverse: Remove noise step by step\")\n",
        "\n",
        "        # Original clean data\n",
        "        self.clean_data = [5, 5, 5, 5]  # Clean signal\n",
        "        print(f\"Clean data: {self.clean_data}\")\n",
        "        print()\n",
        "\n",
        "    def add_noise_step(self, data, noise_level):\n",
        "        \"\"\"Add noise to data (forward diffusion)\"\"\"\n",
        "        noisy_data = []\n",
        "        for value in data:\n",
        "            noise = random.uniform(-noise_level, noise_level)\n",
        "            noisy_data.append(value + noise)\n",
        "\n",
        "        print(f\"Add noise (level {noise_level}): {[round(x, 1) for x in noisy_data]}\")\n",
        "        return noisy_data\n",
        "\n",
        "    def remove_noise_step(self, noisy_data, noise_level):\n",
        "        \"\"\"Remove noise from data (reverse diffusion)\"\"\"\n",
        "        # Simplified denoising: move towards expected clean value\n",
        "        denoised_data = []\n",
        "        for value in noisy_data:\n",
        "            # Simple denoising: move towards center value (5)\n",
        "            denoised = value + 0.3 * (5 - value)  # Move 30% towards clean value\n",
        "            denoised_data.append(denoised)\n",
        "\n",
        "        print(f\"Remove noise: {[round(x, 1) for x in denoised_data]}\")\n",
        "        return denoised_data\n",
        "\n",
        "    def diffusion_process(self):\n",
        "        \"\"\"Complete diffusion process: noise addition then removal\"\"\"\n",
        "        print(\"=== FORWARD DIFFUSION (Adding Noise) ===\")\n",
        "        current_data = self.clean_data.copy()\n",
        "\n",
        "        # Add noise in steps\n",
        "        for step in range(1, 4):\n",
        "            current_data = self.add_noise_step(current_data, step)\n",
        "\n",
        "        print(\"\\n=== REVERSE DIFFUSION (Removing Noise) ===\")\n",
        "\n",
        "        # Remove noise in steps\n",
        "        for step in range(3, 0, -1):\n",
        "            current_data = self.remove_noise_step(current_data, step)\n",
        "\n",
        "        print(f\"Final reconstructed: {[round(x, 1) for x in current_data]}\")\n",
        "        print(f\"Original clean data: {self.clean_data}\")\n",
        "        return current_data"
      ],
      "metadata": {
        "id": "dMNpx3tDCWpq"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Demo all generative models\n",
        "print(\"=== EMERGING DIRECTIONS DEMO ===\")\n",
        "\n",
        "# LLM Demo\n",
        "llm = SimpleLLM()\n",
        "llm.generate_text(\"the cat\", max_length=6)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aE9eFwEsCaFD",
        "outputId": "796521a0-fb8f-4851-f20e-57b4c349eacf"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== EMERGING DIRECTIONS DEMO ===\n",
            "=== Simple LLM INITIALIZED ===\n",
            "Vocabulary size: 10\n",
            "Context window: 5\n",
            "\n",
            "=== TEXT GENERATION ===\n",
            "Prompt: 'the cat'\n",
            "Tokenization: 'the cat' → ['the', 'cat']\n",
            "Context: ['the', 'cat']\n",
            "Attention: 'cat' → possible next: ['sits', 'runs', 'is', 'happy']\n",
            "Generated token: sits\n",
            "Step 1: the cat sits\n",
            "Context: ['the', 'cat', 'sits']\n",
            "Attention: 'sits' → possible next: ['on', 'the']\n",
            "Generated token: the\n",
            "Step 2: the cat sits the\n",
            "Context: ['the', 'cat', 'sits', 'the']\n",
            "Attention: 'the' → possible next: ['cat', 'dog', 'mat', 'park']\n",
            "Generated token: mat\n",
            "Step 3: the cat sits the mat\n",
            "Context: ['the', 'cat', 'sits', 'the', 'mat']\n",
            "Generated token: the\n",
            "Step 4: the cat sits the mat the\n",
            "Final output: 'the cat sits the mat the'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GAN Demo\n",
        "gan = SimpleGAN()\n",
        "for round_num in range(3):\n",
        "    print(f\"Round {round_num + 1}:\")\n",
        "    gan.train_one_round()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yH08X7B5Cc8G",
        "outputId": "58618319-5173-4b5a-b0ee-e4142a999b99"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Simple GAN ===\n",
            "Two networks competing: Generator vs Discriminator\n",
            "Real data patterns: [[1, 1, 0, 0], [0, 0, 1, 1], [1, 0, 1, 0]]\n",
            "\n",
            "Round 1:\n",
            "=== GAN TRAINING ROUND ===\n",
            "Generator created: [1, 0, 1, 0]\n",
            "Discriminator judges [1, 0, 1, 0] as FAKE\n",
            "Actual truth: REAL\n",
            "Generator improved!\n",
            "Generator skill: 0.2\n",
            "Discriminator skill: 0.1\n",
            "\n",
            "Round 2:\n",
            "=== GAN TRAINING ROUND ===\n",
            "Generator created: [0, 1, 0, 1]\n",
            "Discriminator judges [0, 1, 0, 1] as FAKE\n",
            "Actual truth: FAKE\n",
            "Discriminator improved!\n",
            "Generator skill: 0.2\n",
            "Discriminator skill: 0.2\n",
            "\n",
            "Round 3:\n",
            "=== GAN TRAINING ROUND ===\n",
            "Generator created: [0, 0, 1, 1]\n",
            "Discriminator judges [0, 0, 1, 1] as REAL\n",
            "Actual truth: REAL\n",
            "Discriminator improved!\n",
            "Generator skill: 0.2\n",
            "Discriminator skill: 0.3\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VAE Demo\n",
        "vae = SimpleVAE()\n",
        "for i in range(2):\n",
        "    encoded = vae.encode_to_latent(vae.data_points[i])\n",
        "    decoded = vae.decode_from_latent(encoded)\n",
        "vae.generate_new_sample()\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PplWleWRCe2z",
        "outputId": "94ad9e52-78c5-49b8-a77e-1a1a0f1ae45f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Simple VAE ===\n",
            "Encode data → Latent space → Decode data\n",
            "Training data: [[1, 1], [1, 2], [2, 1], [2, 2], [5, 5], [5, 6], [6, 5], [6, 6]]\n",
            "\n",
            "Encode [1, 1] → latent: 0.97\n",
            "Decode latent 0.97 → [0.5, 1.3]\n",
            "Encode [1, 2] → latent: 1.46\n",
            "Decode latent 1.46 → [1.1, 1.1]\n",
            "=== VAE GENERATION ===\n",
            "Sampled latent: 4.73\n",
            "Decode latent 4.73 → [5.1, 4.4]\n",
            "Generated new sample: [5.1, 4.4]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Diffusion Demo\n",
        "diffusion = SimpleDiffusion()\n",
        "diffusion.diffusion_process()\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXmTjQiaCg4q",
        "outputId": "16d74b35-7613-4638-c38c-73461287c0c6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Simple Diffusion Model ===\n",
            "Forward: Add noise step by step\n",
            "Reverse: Remove noise step by step\n",
            "Clean data: [5, 5, 5, 5]\n",
            "\n",
            "=== FORWARD DIFFUSION (Adding Noise) ===\n",
            "Add noise (level 1): [5.8, 4.9, 5.5, 6.0]\n",
            "Add noise (level 2): [4.0, 6.4, 6.9, 5.1]\n",
            "Add noise (level 3): [2.1, 4.0, 8.7, 8.0]\n",
            "\n",
            "=== REVERSE DIFFUSION (Removing Noise) ===\n",
            "Remove noise: [3.0, 4.3, 7.6, 7.1]\n",
            "Remove noise: [3.6, 4.5, 6.8, 6.5]\n",
            "Remove noise: [4.0, 4.7, 6.3, 6.0]\n",
            "Final reconstructed: [4.0, 4.7, 6.3, 6.0]\n",
            "Original clean data: [5, 5, 5, 5]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### limitation of frontier AI system"
      ],
      "metadata": {
        "id": "ran3AxhwCopl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AILimitationsDemo:\n",
        "    \"\"\"Demonstrates key limitations of current AI systems\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        print(\"=== AI LIMITATIONS DEMONSTRATION ===\")\n",
        "        print()\n",
        "\n",
        "    def demonstrate_hallucinations(self):\n",
        "        print(\"=== HALLUCINATION PROBLEM ===\")\n",
        "        print()\n",
        "\n",
        "        # Simulate AI knowledge base with gaps\n",
        "        knowledge_base = {\n",
        "            \"Paris\": \"Capital of France, population 2.1 million\",\n",
        "            \"London\": \"Capital of UK, population 8.9 million\"\n",
        "        }\n",
        "\n",
        "        queries = [\"Paris\", \"Tokyo\", \"Atlantis\"]\n",
        "\n",
        "        for query in queries:\n",
        "            print(f\"Query: What do you know about {query}?\")\n",
        "\n",
        "            if query in knowledge_base:\n",
        "                print(f\"AI Response: {knowledge_base[query]}\")\n",
        "                print(\"Status: ✓ Accurate\")\n",
        "            else:\n",
        "                # AI hallucinates when it doesn't know\n",
        "                fake_facts = [\n",
        "                    f\"{query} is a major city with population 3.2 million\",\n",
        "                    f\"{query} was founded in 1847 and is known for its architecture\",\n",
        "                    f\"{query} has a famous university established in 1923\"\n",
        "                ]\n",
        "                hallucination = random.choice(fake_facts)\n",
        "                print(f\"AI Response: {hallucination}\")\n",
        "                print(\"Status: ❌ HALLUCINATION (False but confident)\")\n",
        "            print()\n",
        "\n",
        "    def demonstrate_generalization_issues(self):\n",
        "        \"\"\"Shows how AI struggles with out-of-distribution examples\"\"\"\n",
        "        print(\"=== GENERALIZATION PROBLEM ===\")\n",
        "        print(\"AI fails on examples outside training distribution\")\n",
        "        print()\n",
        "\n",
        "        # Simulate training on specific patterns\n",
        "        training_patterns = [\n",
        "            {\"input\": [1, 2], \"output\": 3, \"rule\": \"sum\"},\n",
        "            {\"input\": [2, 3], \"output\": 5, \"rule\": \"sum\"},\n",
        "            {\"input\": [3, 4], \"output\": 7, \"rule\": \"sum\"},\n",
        "        ]\n",
        "\n",
        "        print(\"Training examples:\")\n",
        "        for pattern in training_patterns:\n",
        "            print(f\"  {pattern['input']} → {pattern['output']}\")\n",
        "\n",
        "        print(\"AI learns: Output = Input1 + Input2\")\n",
        "        print()\n",
        "\n",
        "        # Test cases\n",
        "        test_cases = [\n",
        "            {\"input\": [4, 5], \"expected\": 9, \"type\": \"similar\"},\n",
        "            {\"input\": [100, 200], \"expected\": 300, \"type\": \"different scale\"},\n",
        "            {\"input\": [-1, -2], \"expected\": -3, \"type\": \"negative numbers\"},\n",
        "            {\"input\": [1.5, 2.5], \"expected\": 4.0, \"type\": \"decimals\"}\n",
        "        ]\n",
        "\n",
        "        print(\"Test results:\")\n",
        "        for test in test_cases:\n",
        "            actual = sum(test[\"input\"])  # Perfect AI would get this right\n",
        "\n",
        "            if test[\"type\"] == \"similar\":\n",
        "                # AI does well on similar examples\n",
        "                predicted = actual\n",
        "                success = True\n",
        "            else:\n",
        "                # AI struggles with different distributions\n",
        "                predicted = actual + random.uniform(-2, 2)  # Add error\n",
        "                success = abs(predicted - test[\"expected\"]) < 0.1\n",
        "\n",
        "            print(f\"  {test['input']} → Predicted: {predicted:.1f}, Expected: {test['expected']}\")\n",
        "            print(f\"    Type: {test['type']} - {'✓ Success' if success else '❌ Failed'}\")\n",
        "        print()\n",
        "\n",
        "    def demonstrate_uncertainty_issues(self):\n",
        "        \"\"\"Shows how AI struggles with uncertainty quantification\"\"\"\n",
        "        print(\"=== UNCERTAINTY PROBLEM ===\")\n",
        "        print(\"AI often can't express how confident it is\")\n",
        "        print()\n",
        "\n",
        "        # Simulate different confidence scenarios\n",
        "        scenarios = [\n",
        "            {\"question\": \"What is 2+2?\", \"confidence\": 0.99, \"correct\": True},\n",
        "            {\"question\": \"Will it rain tomorrow?\", \"confidence\": 0.95, \"correct\": False},\n",
        "            {\"question\": \"What is the capital of Atlantis?\", \"confidence\": 0.90, \"correct\": False}\n",
        "        ]\n",
        "\n",
        "        print(\"AI Confidence vs Reality:\")\n",
        "        for scenario in scenarios:\n",
        "            print(f\"Question: {scenario['question']}\")\n",
        "            print(f\"AI Confidence: {scenario['confidence']*100:.0f}%\")\n",
        "            print(f\"Actually Correct: {'Yes' if scenario['correct'] else 'No'}\")\n",
        "\n",
        "            if scenario['confidence'] > 0.8 and not scenario['correct']:\n",
        "                print(\"❌ Problem: High confidence but wrong!\")\n",
        "            elif scenario['confidence'] < 0.6 and scenario['correct']:\n",
        "                print(\"⚠️  Problem: Low confidence but actually right!\")\n",
        "            else:\n",
        "                print(\"✓ Confidence matches correctness\")\n",
        "            print()\n",
        "\n",
        "        print(\"Key Issue: AI should say 'I don't know' more often!\")\n",
        "        print()"
      ],
      "metadata": {
        "id": "JETQxWjxCsA2"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ethical challenges in AI system"
      ],
      "metadata": {
        "id": "Qmt6UV4RDJfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AIEthicsDemo:\n",
        "    \"\"\"Demonstrates key ethical challenges in AI deployment\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        print(\"=== AI ETHICS CHALLENGES ===\")\n",
        "        print()\n",
        "\n",
        "    def demonstrate_bias_problem(self):\n",
        "        \"\"\"Shows how AI can perpetuate societal biases\"\"\"\n",
        "        print(\"=== BIAS PROBLEM ===\")\n",
        "        print(\"AI systems can amplify human biases from training data\")\n",
        "        print()\n",
        "\n",
        "        # Simulate biased training data\n",
        "        hiring_data = [\n",
        "            {\"name\": \"John\", \"gender\": \"M\", \"degree\": \"CS\", \"hired\": True},\n",
        "            {\"name\": \"Mike\", \"gender\": \"M\", \"degree\": \"CS\", \"hired\": True},\n",
        "            {\"name\": \"Sarah\", \"gender\": \"F\", \"degree\": \"CS\", \"hired\": False},\n",
        "            {\"name\": \"Anna\", \"gender\": \"F\", \"degree\": \"CS\", \"hired\": False},\n",
        "            {\"name\": \"David\", \"gender\": \"M\", \"degree\": \"Math\", \"hired\": True},\n",
        "            {\"name\": \"Lisa\", \"gender\": \"F\", \"degree\": \"Math\", \"hired\": False}\n",
        "        ]\n",
        "\n",
        "        print(\"Historical hiring data (biased):\")\n",
        "        for record in hiring_data:\n",
        "            print(f\"  {record['name']} ({record['gender']}, {record['degree']}) → {'Hired' if record['hired'] else 'Rejected'}\")\n",
        "\n",
        "        # AI learns biased pattern\n",
        "        male_hire_rate = sum(1 for r in hiring_data if r['gender'] == 'M' and r['hired']) / sum(1 for r in hiring_data if r['gender'] == 'M')\n",
        "        female_hire_rate = sum(1 for r in hiring_data if r['gender'] == 'F' and r['hired']) / sum(1 for r in hiring_data if r['gender'] == 'F')\n",
        "\n",
        "        print(f\"\\nAI learned pattern:\")\n",
        "        print(f\"  Male hire rate: {male_hire_rate*100:.0f}%\")\n",
        "        print(f\"  Female hire rate: {female_hire_rate*100:.0f}%\")\n",
        "        print(\"❌ Problem: AI perpetuates gender bias!\")\n",
        "        print()\n",
        "\n",
        "        # Show impact on new candidates\n",
        "        new_candidates = [\n",
        "            {\"name\": \"Alex\", \"gender\": \"M\", \"degree\": \"CS\"},\n",
        "            {\"name\": \"Emma\", \"gender\": \"F\", \"degree\": \"CS\"}\n",
        "        ]\n",
        "\n",
        "        print(\"New candidate predictions:\")\n",
        "        for candidate in new_candidates:\n",
        "            if candidate['gender'] == 'M':\n",
        "                prediction = \"Likely to be hired\" if male_hire_rate > 0.5 else \"Likely to be rejected\"\n",
        "            else:\n",
        "                prediction = \"Likely to be hired\" if female_hire_rate > 0.5 else \"Likely to be rejected\"\n",
        "\n",
        "            print(f\"  {candidate['name']} ({candidate['gender']}) → {prediction}\")\n",
        "\n",
        "        print(\"❌ Bias amplified: Equally qualified candidates treated differently!\")\n",
        "        print()\n",
        "\n",
        "    def demonstrate_privacy_concerns(self):\n",
        "        \"\"\"Shows privacy issues with AI systems\"\"\"\n",
        "        print(\"=== PRIVACY CONCERNS ===\")\n",
        "        print(\"AI systems can infer sensitive information\")\n",
        "        print()\n",
        "\n",
        "        # Simulate user data\n",
        "        user_activities = [\n",
        "            {\"user\": \"User1\", \"activity\": \"Searches for diabetes symptoms\"},\n",
        "            {\"user\": \"User1\", \"activity\": \"Visits pharmacy websites\"},\n",
        "            {\"user\": \"User1\", \"activity\": \"Reads insurance articles\"},\n",
        "            {\"user\": \"User2\", \"activity\": \"Looks up job interview tips\"},\n",
        "            {\"user\": \"User2\", \"activity\": \"Updates resume\"},\n",
        "            {\"user\": \"User2\", \"activity\": \"Checks competitor salaries\"}\n",
        "        ]\n",
        "\n",
        "        print(\"User activity data:\")\n",
        "        for activity in user_activities:\n",
        "            print(f\"  {activity['user']}: {activity['activity']}\")\n",
        "\n",
        "        print(\"\\nAI inferences:\")\n",
        "\n",
        "        # AI can infer sensitive information\n",
        "        user1_activities = [a['activity'] for a in user_activities if a['user'] == 'User1']\n",
        "        user2_activities = [a['activity'] for a in user_activities if a['user'] == 'User2']\n",
        "\n",
        "        print(\"User1 pattern analysis:\")\n",
        "        print(\"  → Likely has health concerns (diabetes)\")\n",
        "        print(\"  → May be seeking insurance\")\n",
        "        print(\"  ❌ Privacy risk: Health information inferred!\")\n",
        "        print()\n",
        "\n",
        "        print(\"User2 pattern analysis:\")\n",
        "        print(\"  → Likely job searching\")\n",
        "        print(\"  → May be dissatisfied with current job\")\n",
        "        print(\"  ❌ Privacy risk: Employment status inferred!\")\n",
        "        print()\n",
        "\n",
        "    def demonstrate_accountability_problem(self):\n",
        "        \"\"\"Shows accountability challenges with AI decisions\"\"\"\n",
        "        print(\"=== ACCOUNTABILITY PROBLEM ===\")\n",
        "        print(\"Who is responsible when AI makes harmful decisions?\")\n",
        "        print()\n",
        "\n",
        "        # Simulate AI decision-making chain\n",
        "        decision_chain = [\n",
        "            {\"actor\": \"Data Scientists\", \"role\": \"Collected training data\"},\n",
        "            {\"actor\": \"ML Engineers\", \"role\": \"Built the model\"},\n",
        "            {\"actor\": \"Product Team\", \"role\": \"Deployed the system\"},\n",
        "            {\"actor\": \"AI System\", \"role\": \"Made the decision\"},\n",
        "            {\"actor\": \"Company\", \"role\": \"Owns the system\"}\n",
        "        ]\n",
        "\n",
        "        print(\"AI Decision Chain:\")\n",
        "        for link in decision_chain:\n",
        "            print(f\"  {link['actor']}: {link['role']}\")\n",
        "\n",
        "        print(\"\\nScenario: AI loan system denies loan to qualified applicant\")\n",
        "        print(\"\\nAccountability questions:\")\n",
        "        print(\"  • Data Scientists: 'We just collected available data'\")\n",
        "        print(\"  • ML Engineers: 'We optimized for accuracy metrics'\")\n",
        "        print(\"  • Product Team: 'We followed standard deployment process'\")\n",
        "        print(\"  • AI System: 'I processed inputs according to training'\")\n",
        "        print(\"  • Company: 'We used industry-standard AI practices'\")\n",
        "        print()\n",
        "        print(\"❌ Problem: Everyone has plausible deniability!\")\n",
        "        print(\"❌ Result: No clear accountability for harmful outcomes\")\n",
        "        print()\n",
        ""
      ],
      "metadata": {
        "id": "QljaPtShDMeQ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Demo all limitations and ethics\n",
        "limitations_demo = AILimitationsDemo()\n",
        "limitations_demo.demonstrate_hallucinations()\n",
        "limitations_demo.demonstrate_generalization_issues()\n",
        "limitations_demo.demonstrate_uncertainty_issues()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyCtRiLEDRXw",
        "outputId": "a2ef9cf5-026f-4af5-86f5-1fb7948ff92e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== AI LIMITATIONS DEMONSTRATION ===\n",
            "\n",
            "=== HALLUCINATION PROBLEM ===\n",
            "AI generates false information with high confidence\n",
            "\n",
            "Query: What do you know about Paris?\n",
            "AI Response: Capital of France, population 2.1 million\n",
            "Status: ✓ Accurate\n",
            "\n",
            "Query: What do you know about Tokyo?\n",
            "AI Response: Tokyo was founded in 1847 and is known for its architecture\n",
            "Status: ❌ HALLUCINATION (False but confident)\n",
            "\n",
            "Query: What do you know about Atlantis?\n",
            "AI Response: Atlantis is a major city with population 3.2 million\n",
            "Status: ❌ HALLUCINATION (False but confident)\n",
            "\n",
            "=== GENERALIZATION PROBLEM ===\n",
            "AI fails on examples outside training distribution\n",
            "\n",
            "Training examples:\n",
            "  [1, 2] → 3\n",
            "  [2, 3] → 5\n",
            "  [3, 4] → 7\n",
            "AI learns: Output = Input1 + Input2\n",
            "\n",
            "Test results:\n",
            "  [4, 5] → Predicted: 9.0, Expected: 9\n",
            "    Type: similar - ✓ Success\n",
            "  [100, 200] → Predicted: 300.1, Expected: 300\n",
            "    Type: different scale - ❌ Failed\n",
            "  [-1, -2] → Predicted: -3.4, Expected: -3\n",
            "    Type: negative numbers - ❌ Failed\n",
            "  [1.5, 2.5] → Predicted: 6.0, Expected: 4.0\n",
            "    Type: decimals - ❌ Failed\n",
            "\n",
            "=== UNCERTAINTY PROBLEM ===\n",
            "AI often can't express how confident it is\n",
            "\n",
            "AI Confidence vs Reality:\n",
            "Question: What is 2+2?\n",
            "AI Confidence: 99%\n",
            "Actually Correct: Yes\n",
            "✓ Confidence matches correctness\n",
            "\n",
            "Question: Will it rain tomorrow?\n",
            "AI Confidence: 95%\n",
            "Actually Correct: No\n",
            "❌ Problem: High confidence but wrong!\n",
            "\n",
            "Question: What is the capital of Atlantis?\n",
            "AI Confidence: 90%\n",
            "Actually Correct: No\n",
            "❌ Problem: High confidence but wrong!\n",
            "\n",
            "Key Issue: AI should say 'I don't know' more often!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ethics_demo = AIEthicsDemo()\n",
        "ethics_demo.demonstrate_bias_problem()\n",
        "ethics_demo.demonstrate_privacy_concerns()\n",
        "ethics_demo.demonstrate_accountability_problem()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elq8a3n2DT45",
        "outputId": "b36bf88b-b634-4ee0-9794-f5eee4861c77"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== AI ETHICS CHALLENGES ===\n",
            "\n",
            "=== BIAS PROBLEM ===\n",
            "AI systems can amplify human biases from training data\n",
            "\n",
            "Historical hiring data (biased):\n",
            "  John (M, CS) → Hired\n",
            "  Mike (M, CS) → Hired\n",
            "  Sarah (F, CS) → Rejected\n",
            "  Anna (F, CS) → Rejected\n",
            "  David (M, Math) → Hired\n",
            "  Lisa (F, Math) → Rejected\n",
            "\n",
            "AI learned pattern:\n",
            "  Male hire rate: 100%\n",
            "  Female hire rate: 0%\n",
            "❌ Problem: AI perpetuates gender bias!\n",
            "\n",
            "New candidate predictions:\n",
            "  Alex (M) → Likely to be hired\n",
            "  Emma (F) → Likely to be rejected\n",
            "❌ Bias amplified: Equally qualified candidates treated differently!\n",
            "\n",
            "=== PRIVACY CONCERNS ===\n",
            "AI systems can infer sensitive information\n",
            "\n",
            "User activity data:\n",
            "  User1: Searches for diabetes symptoms\n",
            "  User1: Visits pharmacy websites\n",
            "  User1: Reads insurance articles\n",
            "  User2: Looks up job interview tips\n",
            "  User2: Updates resume\n",
            "  User2: Checks competitor salaries\n",
            "\n",
            "AI inferences:\n",
            "User1 pattern analysis:\n",
            "  → Likely has health concerns (diabetes)\n",
            "  → May be seeking insurance\n",
            "  ❌ Privacy risk: Health information inferred!\n",
            "\n",
            "User2 pattern analysis:\n",
            "  → Likely job searching\n",
            "  → May be dissatisfied with current job\n",
            "  ❌ Privacy risk: Employment status inferred!\n",
            "\n",
            "=== ACCOUNTABILITY PROBLEM ===\n",
            "Who is responsible when AI makes harmful decisions?\n",
            "\n",
            "AI Decision Chain:\n",
            "  Data Scientists: Collected training data\n",
            "  ML Engineers: Built the model\n",
            "  Product Team: Deployed the system\n",
            "  AI System: Made the decision\n",
            "  Company: Owns the system\n",
            "\n",
            "Scenario: AI loan system denies loan to qualified applicant\n",
            "\n",
            "Accountability questions:\n",
            "  • Data Scientists: 'We just collected available data'\n",
            "  • ML Engineers: 'We optimized for accuracy metrics'\n",
            "  • Product Team: 'We followed standard deployment process'\n",
            "  • AI System: 'I processed inputs according to training'\n",
            "  • Company: 'We used industry-standard AI practices'\n",
            "\n",
            "❌ Problem: Everyone has plausible deniability!\n",
            "❌ Result: No clear accountability for harmful outcomes\n",
            "\n"
          ]
        }
      ]
    }
  ]
}